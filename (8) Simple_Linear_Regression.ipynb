{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "6eb3c9e7-c17a-5f20-bbbc-2389b74c7a36",
        "openai_ephemeral_user_id": "3af8edfd-ae3a-58ef-80b4-27e8917550be",
        "openai_subdivision1_iso_code": "MX-BCN"
      }
    },
    "noteable": {
      "last_transaction_id": "5b41a9ae-9fae-4ebe-9282-f8d3fd606d8b"
    },
    "selected_hardware_size": "small"
  },
  "cells": [
    {
      "id": "1d08587e-26b8-45d0-a06f-f706628cc68f",
      "cell_type": "markdown",
      "source": "# Understanding Simple Linear Regression\n\nIn this notebook, we will explore the concept of Simple Linear Regression, a fundamental statistical and machine learning method used for predicting a quantitative dependent variable based on a single independent variable. We will go through the theory, assumptions, and implementation of Simple Linear Regression.\n\n## Table of Contents\n\n1. [Introduction to Simple Linear Regression](#section1)\n2. [Assumptions of Simple Linear Regression](#section2)\n3. [Implementing Simple Linear Regression](#section3)\n4. [Interpreting the Results](#section4)\n5. [Conclusion](#section5)",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "6207d4c6-92cb-4438-864f-895984dd729c",
      "cell_type": "markdown",
      "source": "<a id='section1'></a>\n## 1. Introduction to Simple Linear Regression\n\nSimple Linear Regression is a statistical method that allows us to summarize and study relationships between two continuous (quantitative) variables:\n\n1. One variable, denoted x, is regarded as the predictor, explanatory, or independent variable.\n2. The other variable, denoted y, is regarded as the response, outcome, or dependent variable.\n\nThe simple linear regression model is expressed as:\n\ny = β0 + β1x + ε\n\nwhere:\n\n- y is the dependent variable.\n- x is the independent variable.\n- β0 is the y-intercept.\n- β1 is the slope.\n- ε is the error term.\n\nThe goal of simple linear regression is to create a linear model that minimizes the sum of squares of the residuals/error (ε).",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "a4684d63-43d0-4cc5-891e-09872b4de663",
      "cell_type": "markdown",
      "source": "<a id='section2'></a>\n## 2. Assumptions of Simple Linear Regression\n\nSimple Linear Regression makes several assumptions:\n\n- **Linearity**: The relationship between X and the mean of Y is linear.\n- **Homoscedasticity**: The variance of residual is the same for any value of X.\n- **Independence**: Observations are independent of each other.\n- **Normality**: For any fixed value of X, Y is normally distributed.\n\nWhen these assumptions are violated, the reliability of the forecasted values and the insights from the model are questionable.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "19c671e7-fb46-43b5-9a3b-bb42cfe2715a",
      "cell_type": "markdown",
      "source": "<a id='section3'></a>\n## 3. Implementing Simple Linear Regression\n\nIn this section, we will implement Simple Linear Regression using Python's Scikit-Learn library. We will use a hypothetical dataset for this purpose. Let's start by importing the necessary libraries.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "18cd9806-59d2-47e8-92b4-710ab07fbe99",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "b3c3f5df-e717-43ef-8ee3-0d8ae6a1eac1"
        },
        "ExecuteTime": {
          "end_time": "2023-07-04T03:24:30.822110+00:00",
          "start_time": "2023-07-04T03:24:29.895664+00:00"
        }
      },
      "execution_count": null,
      "source": "# Importing necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\n\n# This allows plots to appear directly in the notebook\n%matplotlib inline",
      "outputs": []
    },
    {
      "id": "73066705-d1c8-4017-8a9e-f246824ed4e7",
      "cell_type": "markdown",
      "source": "Now, let's create a hypothetical dataset with one independent variable and one dependent variable.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "f6a3537a-f56c-4fa9-b3f5-2581f6ed32e7",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "1b8df821-f549-4b80-8458-4048ec160c8a"
        },
        "ExecuteTime": {
          "end_time": "2023-07-04T03:24:53.009769+00:00",
          "start_time": "2023-07-04T03:24:52.433749+00:00"
        }
      },
      "execution_count": null,
      "source": "# Creating a hypothetical dataset\nnp.random.seed(0)\nx = np.random.rand(100, 1)\ny = 2 + 3 * x + np.random.rand(100, 1)\n\n# Plotting the dataset\nplt.scatter(x,y,s=10)\nplt.xlabel('x')\nplt.ylabel('y')\nplt.show()",
      "outputs": []
    },
    {
      "id": "b88d972c-8405-48e2-b78b-30b0530baff5",
      "cell_type": "markdown",
      "source": "Next, we will split our dataset into training and testing sets. The training set will be used to train the linear regression model, while the testing set will be used to evaluate the model's performance.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "ca6a8810-3875-4d0a-908a-41064e695fe1",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "edc875ed-ee28-4a98-9d8d-a8dd9c8e8800"
        },
        "ExecuteTime": {
          "end_time": "2023-07-04T03:25:12.721096+00:00",
          "start_time": "2023-07-04T03:25:12.563499+00:00"
        }
      },
      "execution_count": null,
      "source": "# Splitting the dataset into training and testing sets\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)",
      "outputs": []
    },
    {
      "id": "2df6dec2-05f0-4069-bc34-241b17af84af",
      "cell_type": "markdown",
      "source": "Now, we will train our Simple Linear Regression model on the training set using Scikit-Learn's `LinearRegression` class.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "cad18605-5254-4395-9161-aaee570390ca",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "4599ad01-a317-4496-ad31-37b17e7d4867"
        },
        "ExecuteTime": {
          "end_time": "2023-07-04T03:25:33.158757+00:00",
          "start_time": "2023-07-04T03:25:32.996871+00:00"
        }
      },
      "execution_count": null,
      "source": "# Training the Simple Linear Regression model on the training set\nregressor = LinearRegression()\nregressor.fit(x_train, y_train)",
      "outputs": []
    },
    {
      "id": "85b89ef8-f66e-4516-bb02-c2b209ff411d",
      "cell_type": "markdown",
      "source": "After training the model, we can obtain the slope and intercept of the regression line.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "9ca9a392-05bb-410a-bdf2-487f96863cd1",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "f7a011cb-e089-4e56-a598-acd53430c043"
        },
        "ExecuteTime": {
          "end_time": "2023-07-04T03:25:55.832754+00:00",
          "start_time": "2023-07-04T03:25:55.675549+00:00"
        }
      },
      "execution_count": null,
      "source": "# Getting parameters\nintercept = regressor.intercept_[0]\nslope = regressor.coef_[0][0]\n\nprint(f'The intercept of the regression line is: {intercept}')\nprint(f'The slope of the regression line is: {slope}')",
      "outputs": []
    },
    {
      "id": "d25e1f1e-9aa6-4164-82f6-d1edd86fe214",
      "cell_type": "markdown",
      "source": "Now, let's use our trained model to make predictions on the testing set and visualize the regression line.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "23560748-0f72-4862-bab5-553e3e4a8f06",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "a4a7a733-cb83-44ad-8644-514cacfd55c4"
        },
        "ExecuteTime": {
          "end_time": "2023-07-04T03:26:31.223246+00:00",
          "start_time": "2023-07-04T03:26:30.400054+00:00"
        }
      },
      "execution_count": null,
      "source": "# Making predictions\ny_pred = regressor.predict(x_test)\n\n# Visualizing the training set results\nplt.scatter(x_train, y_train, color = 'red')\nplt.plot(x_train, regressor.predict(x_train), color = 'blue')\nplt.title('Training set')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.show()\n\n# Visualizing the test set results\nplt.scatter(x_test, y_test, color = 'red')\nplt.plot(x_train, regressor.predict(x_train), color = 'blue')\nplt.title('Test set')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.show()",
      "outputs": []
    },
    {
      "id": "5ab4d351-8c89-45da-86b1-b14d05a20781",
      "cell_type": "markdown",
      "source": "<a id='section4'></a>\n## 4. Interpreting the Results\n\nThe slope and intercept of the regression line are known as the model coefficients or parameters. In our case:\n\n- The y-intercept (β0) is around 2.58. This means that if the x variable (independent variable) is zero, then the expected output (y or dependent variable) would be 2.58.\n- The slope (β1) is around 2.91. This means that for each one unit change in x, the change in y is about 2.91.\n\nThe blue lines in the plots above represent the regression line, which is the best fit line through the data points. As we can see, the model seems to fit the data quite well.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "9c2ae0ee-986f-490f-9a1a-5a4f7c8f4d38",
      "cell_type": "markdown",
      "source": "<a id='section5'></a>\n## 5. Conclusion\n\nIn this notebook, we have gone through the basics of Simple Linear Regression, its assumptions, and its implementation using Python's Scikit-Learn library. We have also interpreted the results of our model.\n\nSimple Linear Regression is a powerful tool for understanding the linear relationships between two variables, and it's a fundamental technique in statistical learning and machine learning. However, it's important to remember that it makes several assumptions about the data, and if these assumptions are violated, the results may not be reliable.\n\nIn the real world, data is often more complex and may require more sophisticated models. But understanding Simple Linear Regression is a good starting point for diving into more complex regression models and machine learning techniques.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    }
  ]
}
